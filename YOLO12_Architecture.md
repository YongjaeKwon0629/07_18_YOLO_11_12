# ğŸ§¬ YOLO V12: ë„¤íŠ¸ì›Œí¬ ì•„í‚¤í…ì²˜ ìƒì„¸ ë¶„ì„

---

<div align="center">

<img src="https://img.icons8.com/color/96/structure.png" width="70" alt="Architecture Icon"/>
<br>
<b style="font-size:1.2em;">Attention & Transformer ê¸°ë°˜ ì´ˆì‹¤ì‹œê°„ ê°ì²´ íƒì§€ ë„¤íŠ¸ì›Œí¬ì˜ í˜ì‹ ì  ì„¤ê³„</b>

</div>

---

## 1. ì•„í‚¤í…ì²˜ ê°œìš”

YOLO V12ëŠ” ìµœì‹  TransformerÂ·Attention ë©”ì»¤ë‹ˆì¦˜ì„ ì¤‘ì‹¬ìœ¼ë¡œ,  
CNNì˜ ê³µê°„ì  íŠ¹ì§• í•™ìŠµë ¥ê³¼ íŠ¸ëœìŠ¤í¬ë¨¸ì˜ ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸ ì¸ì§€ëŠ¥ë ¥ì„ ìœµí•©í•œ í•˜ì´ë¸Œë¦¬ë“œ êµ¬ì¡°ì…ë‹ˆë‹¤.

- **End-to-End ì‹¤ì‹œê°„ íƒì§€**ì™€ **ë©€í‹°ìŠ¤ì¼€ì¼ í†µí•©**,  
- **ëª¨ë“ˆë³„ ë…ë¦½ ì—…ê·¸ë ˆì´ë“œ** ë° **ìœ ì—°í•œ ì´ì‹ì„±**ì„ ê°•ì ìœ¼ë¡œ í•˜ì—¬  
- í•˜ë“œì›¨ì–´, ë°ì´í„° ì„¸íŠ¸, ì‘ìš© ëª©ì ì— ë”°ë¼ ìµœì ì˜ ì„±ëŠ¥ì„ ìœ ì—°íˆ ì œê³µí•©ë‹ˆë‹¤.

---

## 2. ì£¼ìš” ë¸”ë¡ë³„ ìƒì„¸ êµ¬ì¡°

### 2.1 Transformer-Attention Backbone

- **Hybrid Patch Embedding**  
  - ì´ë¯¸ì§€ë¥¼ íŒ¨ì¹˜ í˜•íƒœë¡œ ë¶„í•´(Transformer) + Convolutional Pre-processing
  - ê³µê°„ í•´ìƒë„-ì±„ë„ ì¡°í™”ë¡­ê²Œ ë³´ì¡´
- **Multi-Scale Self-Attention Layers**  
  - ê° ìŠ¤í…Œì´ì§€ì—ì„œ ë…ë¦½ì  self-attention map ìƒì„±  
  - ê¸€ë¡œë²Œ ì»¨í…ìŠ¤íŠ¸: ê¸´ ê±°ë¦¬ì˜ ê°ì²´Â·ë°°ê²½ ìƒê´€ê´€ê³„ê¹Œì§€ ëª¨ë¸ë§ ê°€ëŠ¥
- **Channel-wise Adaptive Fusion**  
  - ì±„ë„ë§ˆë‹¤ attention ê°€ì¤‘ì¹˜ ì ì‘ì ìœ¼ë¡œ ë¶€ì—¬  
  - ë¯¸ì„¸ íŒ¨í„´/ë¡œì»¬ í”¼ì²˜ upweight, ë°°ê²½ë…¸ì´ì¦ˆ downweight
- **Residual & Layer Normalization**  
  - ë”¥ ë„¤íŠ¸ì›Œí¬ ì•ˆì •ì  ìˆ˜ë ´ê³¼ ë¶„ì‚° ì œì–´, í•™ìŠµ ì†ë„ ê°œì„ 

#### â—¾ ì˜ˆì‹œ ë„¤íŠ¸ì›Œí¬ íë¦„



---

### 2.2 Multi-Scale Feature Aggregation Neck

- **FPN(Feature Pyramid Network) ê³„ì—´ í™•ì¥**  
  - ì €ì¸µ~ê³ ì¸µ í”¼ì²˜ë¥¼ ìƒí–¥/í•˜í–¥ ìƒ˜í”Œë§ í›„,  
  - ê° í•´ìƒë„ë³„ Feature Mapì„ ë™ì ìœ¼ë¡œ ê²°í•©
- **PANet ë° Path Fusion**  
  - Top-down & Bottom-up path ìŒë°©í–¥ ì—°ê²°  
  - Fine/Coarse ì •ë³´ê°€ ê³µì¡´í•˜ëŠ” ë³µí•© í™˜ê²½ì—ì„œ íš¨ê³¼ì 
- **Attention-Based Fusion Layer**  
  - Spatial/Channel Attentionìœ¼ë¡œ object-relevant zoneë§Œ ê°•í™”  
  - Multi-head êµ¬ì¡°ë¡œ ì˜¤ë¥˜ íƒì§€Â·ì‘ì€ ê°ì²´ ê°ë„ ëŒ€í­ í–¥ìƒ

#### â—¾ ì£¼ìš” Neck Layer êµ¬ì„± ì˜ˆ

| ë ˆì´ì–´          | ì—°ì‚° | ì„¤ëª…                       |
|-----------------|------|---------------------------|
| FPN-PAN         | +    | Pyramid + ê²½ë¡œì§‘ì•½         |
| SA Module       | âŠ•    | Spatial Attention ëª¨ë“ˆ     |
| CA Module       | âŠ•    | Channel Attention ëª¨ë“ˆ     |
| AGG Block       | âŠ•    | Aggregation & Skip Fusion |

---

### 2.3 Detection Head (ìœ ì—°Â·í™•ì¥í˜• êµ¬ì¡°)

- **Hybrid Anchor/Anchor-Free Head**  
  - Classification: ììœ ë¡œìš´ Head Branch ì„¤ê³„ ê°€ëŠ¥  
  - Localization: Anchor-Free(heatmap/centroid), Anchor-based(ê¸°ì¡´ YOLO ê³„ì—´) ì„ íƒ íƒ‘ì¬  
  - ìŠ¤ì¼€ì¼ ì ì‘í˜•ìœ¼ë¡œ Headë³„ receptive field ì¡°ì •
- **IoU-Aware & Distribution Focal Loss**  
  - ìœ„ì¹˜ ì˜ˆì¸¡: GIoU/DIoU/CIoU Lossë¡œ ê²½ê³„Â·ì¤‘ì‹¬Â·í˜•íƒœê¹Œì§€ ì—„ë°€ ì •í•©
  - ë¶„í¬ ê¸°ë°˜ Focal Loss â†’ foreground/background imbalance ì™„í™”+Class focus  
- **Multi-Task Output Layer**  
  - Class, Box, (option) Mask/Instance ë“± ë‹¤ì–‘í•œ task ë³‘ë ¬ ì¶œë ¥ êµ¬ì¡° ì§€ì›  
  - ONNX/TensorRT ë“± ì‹¤ì „ ë°°í¬ í¬ë§· ë³€í™˜ ìµœì 

---

## 3. ë„¤íŠ¸ì›Œí¬ ë ˆì´ì–´Â·ë¸”ë¡ë³„ ìš”ì•½ í‘œ

| ì»´í¬ë„ŒíŠ¸                 | ì£¼ìš” ëª¨ë“ˆ/ì—°ì‚°         | ì•„í‚¤í…ì²˜ íŠ¹ì¥ì                                 |
|--------------------------|-----------------------|------------------------------------------------|
| Backbone                 | Patch+Conv, Multi-Stage Transformer, Residual, LN | ê¸€ë¡œë²Œ-ë¡œì»¬ í”¼ì²˜ ìœµí•©, ë”¥ êµ¬ì¡°+íš¨ìœ¨ì  í•™ìŠµ          |
| Neck                     | FPN+PAN, AGG, SA/CA   | ë©€í‹°ìŠ¤ì¼€ì¼ ë‹¤ì–‘ì„±, ì˜¤ë¥˜Zone ì†Œê±°, ì‘ì€ ê°ì²´ ê°•í™”     |
| Detection Head           | Hybrid Head, IoU Loss, DFL | ìœ„ì¹˜/í´ë˜ìŠ¤ ë™ì‹œ í•™ìŠµ, í´ë˜ìŠ¤/ë°°ê²½ ë¶ˆê· í˜• ì™„í™”       |
| Output                   | Multi-task (Box/Class/Mask) | ì‹¤ì „ ë§ì¶¤í˜• Task ë³‘ë ¬ ì§€ì›, ìœ ì—° ë°°í¬               |

---

## 4. ì½”ë“œ/êµ¬ì„± ì˜ˆì‹œ (PyTorch ìŠ¤íƒ€ì¼)

```
class YoloV12(nn.Module):
def init(self, ...):
super().init()
self.backbone = TransformerBackbone(stages=[...], patch_size=16)
self.neck = FPNPANNeck(num_heads=4, agg_method='attention')
self.head = DetectionHead(anchor_free=True, iou_loss='ciou', num_classes=80)
def forward(self, x):
feats = self.backbone(x)
fusion = self.neck(feats)
out = self.head(fusion)
return out
```
*ì‹¤ì œ êµ¬í˜„ì—ì„œëŠ” í•˜ì´í¼íŒŒë¼ë¯¸í„°, Attention type ë“± ìˆ˜ì‹­ê°€ì§€ ì„¸ë¶€ ì˜µì…˜ì´ ë³„ë„ ê´€ë¦¬ë¨*

---

## 5. ì´ë¡ ì  ë…¼ì˜ ë° í˜ì‹ ì  ì‹œì‚¬ì 

- **Transformer ë„ì…ì˜ ì´ë¡ ì  ë³€ê³¡ì **
    - ì¼ë°˜ CNN ëŒ€ë¹„ ì „ì²´ ì¥ë©´Â·ê°ì²´í–‰ë™ íŒ¨í„´ì„ globalí•˜ê²Œ í•™ìŠµ
    - ë°ì´í„°ì…‹ ë¶„í¬/Scene varietyì— ê°•ì¸, ë“œë¬¼ê±°ë‚˜ ë¯¸ì„¸í•œ ê°ì²´ì—ë„ ì˜¤íƒ ìµœì†Œí™”
- **Multi-Scale & Fusionì˜ í†µí•© íš¨ê³¼**
    - ì €í•´ìƒë„/ê³ í•´ìƒë„ ì •ë³´ì˜ ë™ì‹œ ì§‘ì (ë¶€ë¶„ ì •ë³´ì˜ ë¡œìŠ¤ ë°©ì§€)
    - ìŠ¤í‚µ, Residual, Adaptive Fusion ë“± ë‹¤ì–‘í•œ ê²°í•© ê²½ë¡œâ†’ë‹¤ì¤‘ ê·œëª¨ ê°ì²´ ë™ì‹œ íƒì§€
- **Anchor-FreeÂ·Anchor í˜¼í•© Head**
    - ë°ì´í„°/í™˜ê²½ì— ë”°ë¼ ì í•© êµ¬ì¡° ì¦‰ì‹œ ì „í™˜ ê°€ëŠ¥(GeneralizationÂ·tuning ìœ ë¦¬)
    - Segmentation, Counting ë“± ì „ì´Â·í™•ì¥ê¹Œì§€ ìœ ì—° ëŒ€ì‘

> YOLO V12 ì•„í‚¤í…ì²˜ëŠ” â€œë”¥ ì˜¤ë¸Œì íŠ¸ íƒì§€ ë„¤íŠ¸ì›Œí¬ì˜ Moduleization, Global-Local Feature í†µí•©, ì‹¤ì „ ë°°í¬ íš¨ìœ¨ì„±â€ ì„¸ ìš”ì†Œë¥¼ ê°€ì¥ í˜„ëŒ€ì ìœ¼ë¡œ ì‹¤í˜„í•©ë‹ˆë‹¤.

---

## 6. ë„ì‹ì  êµ¬ì¡° íë¦„ ìš”ì•½


---

## 7. ì°¸ê³  ë¬¸í—Œ ë° ì‹¬ì¸µ íƒêµ¬ ìë£Œ

- Dosovitskiy et al. "An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale" (ViT, ICLR 2021)
- Wang et al. "CBNetV2: A Composite Backbone Network Architecture for Object Detection" (CVPR 2021)
- Bochkovskiy et al. "YOLOv4: Optimal Speed and Accuracy of Object Detection" (arXiv:2004.10934)
- Zhu et al. "Deformable DETR: Deformable Transformers for End-to-End Object Detection" (ICLR 2021)

---
